{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 8 - Question.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYtuKeK0dImp"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMyh9_mkDHF"
      },
      "source": [
        "The data for this exercise is available at: https://www.kaggle.com/datamunge/sign-language-mnist/home\n",
        "\n",
        "Sign up and download to find 2 CSV files: sign_mnist_test.csv and sign_mnist_train.csv -- You will upload both of them using this button before you can continue.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "IcLOZlnnc_N7",
        "outputId": "1829e82b-f64d-4919-d74e-83e4138f52d4"
      },
      "source": [
        "uploaded=files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-64d4089b-7ea1-48a0-99b1-49f319664199\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-64d4089b-7ea1-48a0-99b1-49f319664199\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sign_mnist_test.csv to sign_mnist_test.csv\n",
            "Saving sign_mnist_train.csv to sign_mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kxw-_rmcnVu",
        "outputId": "e5ca4b3e-2f87-4952-8ed2-8b78c6c5a26e"
      },
      "source": [
        "def get_data(filename):\n",
        "  # You will need to write code that will read the file passed\n",
        "  # into this function. The first line contains the column headers\n",
        "  # so you should ignore it\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\n",
        "  # The first value is the label\n",
        "  # The rest are the pixel values for that picture\n",
        "  # The function will return 2 np.array types. One with all the labels\n",
        "  # One with all the images\n",
        "  #\n",
        "  # Tips: \n",
        "  # If you read a full line (as 'row') then row[0] has the label\n",
        "  # and row[1:785] has the 784 pixel values\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
        "  # You are reading in strings, but need the values to be floats\n",
        "  # Check out np.array().astype for a conversion\n",
        "    labels= []\n",
        "    images = []\n",
        "    with open(filename) as training_file:\n",
        "      # Your code starts here\n",
        "        filelines = csv.reader(training_file)        \n",
        "        for i, line in enumerate(filelines):\n",
        "            if (i>=1):\n",
        "                labels.append( line[0])\n",
        "                images.append( np.asarray(line[1:785], dtype=float).reshape(28,28) )\n",
        "                \n",
        "    labels = np.asarray(labels, dtype=int)\n",
        "    images = np.asarray(images, dtype=float)\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "training_images, training_labels = get_data('sign_mnist_train.csv')\n",
        "testing_images, testing_labels = get_data('sign_mnist_test.csv')\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28)\n",
        "# (27455,)\n",
        "# (7172, 28, 28)\n",
        "# (7172,)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27455, 28, 28)\n",
            "(27455,)\n",
            "(7172, 28, 28)\n",
            "(7172,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awoqRpyZdQkD",
        "outputId": "3eb5853c-a1b1-422e-c323-a3a6a282c708"
      },
      "source": [
        "# In this section you will have to add another dimension to the data\n",
        "# So, for example, if your array is (10000, 28, 28)\n",
        "# You will need to make it (10000, 28, 28, 1)\n",
        "# Hint: np.expand_dims\n",
        "\n",
        "training_images = np.expand_dims(training_images , axis=3 ) # Your Code Here\n",
        "testing_images = np.expand_dims(testing_images , axis=3 )# Your Code Here\n",
        "\n",
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t  rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "training_labels = np.eye(25)[training_labels]\n",
        "\n",
        "train_generator = training_datagen.flow(\n",
        "\ttraining_images,\n",
        "    training_labels,\n",
        "    batch_size= 16\n",
        ")\n",
        "\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        ")\n",
        "testing_labels =  np.eye(25)[testing_labels]\n",
        "validation_generator = validation_datagen.flow(\n",
        "\ttesting_images,\n",
        "    testing_labels,\n",
        "  batch_size = 16\n",
        ")\n",
        "    \n",
        "# Keep These\n",
        "print(training_images.shape)\n",
        "print(testing_images.shape)\n",
        "    \n",
        "# Their output should be:\n",
        "# (27455, 28, 28, 1)\n",
        "# (7172, 28, 28, 1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27455, 28, 28, 1)\n",
            "(7172, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t3ZqLaK8yET"
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 97.0%\r\n",
        "class myCallback(tf.keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        acc = logs['accuracy']\r\n",
        "        if(acc >= 0.97):\r\n",
        "            print(\"\\nReached 97.0% accuracy so cancelling training!\")\r\n",
        "            self.model.stop_training = True   "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmb7S32cgRqS",
        "outputId": "911924a2-856f-4ad2-df0b-eb25c1275041"
      },
      "source": [
        "# Define the model\n",
        "# Use no more than 2 Conv2D and 2 MaxPooling2D\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dropout(0.2),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(25, activation='softmax')\n",
        "])\n",
        "\n",
        "print(model.summary())\n",
        "# Compile Model. \n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(train_generator\n",
        "                    , epochs=50\n",
        "                    , validation_data=validation_generator \n",
        "                    ,callbacks = [ myCallback() ]  )\n",
        "\n",
        "model.evaluate(testing_images, testing_labels , verbose=0)\n",
        "    \n",
        "# The output from model.evaluate should be close to:\n",
        "[6.92426086682151, 0.56609035]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 25)                1625      \n",
            "=================================================================\n",
            "Total params: 3,435,673\n",
            "Trainable params: 3,435,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 2.9965 - accuracy: 0.0928 - val_loss: 1.6554 - val_accuracy: 0.3929\n",
            "Epoch 2/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 1.7698 - accuracy: 0.3952 - val_loss: 1.1295 - val_accuracy: 0.5832\n",
            "Epoch 3/50\n",
            "1716/1716 [==============================] - 118s 69ms/step - loss: 1.2339 - accuracy: 0.5659 - val_loss: 0.8226 - val_accuracy: 0.6928\n",
            "Epoch 4/50\n",
            "1716/1716 [==============================] - 118s 69ms/step - loss: 0.9682 - accuracy: 0.6586 - val_loss: 0.6375 - val_accuracy: 0.7450\n",
            "Epoch 5/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 0.7957 - accuracy: 0.7166 - val_loss: 0.5171 - val_accuracy: 0.7949\n",
            "Epoch 6/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.6811 - accuracy: 0.7610 - val_loss: 0.4388 - val_accuracy: 0.8289\n",
            "Epoch 7/50\n",
            "1716/1716 [==============================] - 121s 70ms/step - loss: 0.5889 - accuracy: 0.7940 - val_loss: 0.3273 - val_accuracy: 0.8695\n",
            "Epoch 8/50\n",
            "1716/1716 [==============================] - 122s 71ms/step - loss: 0.5336 - accuracy: 0.8137 - val_loss: 0.3473 - val_accuracy: 0.8668\n",
            "Epoch 9/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.4987 - accuracy: 0.8283 - val_loss: 0.3298 - val_accuracy: 0.8818\n",
            "Epoch 10/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.4498 - accuracy: 0.8431 - val_loss: 0.2221 - val_accuracy: 0.9087\n",
            "Epoch 11/50\n",
            "1716/1716 [==============================] - 122s 71ms/step - loss: 0.4032 - accuracy: 0.8551 - val_loss: 0.1858 - val_accuracy: 0.9267\n",
            "Epoch 12/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.4032 - accuracy: 0.8657 - val_loss: 0.2662 - val_accuracy: 0.9074\n",
            "Epoch 13/50\n",
            "1716/1716 [==============================] - 121s 71ms/step - loss: 0.3764 - accuracy: 0.8723 - val_loss: 0.2118 - val_accuracy: 0.9223\n",
            "Epoch 14/50\n",
            "1716/1716 [==============================] - 122s 71ms/step - loss: 0.3553 - accuracy: 0.8770 - val_loss: 0.3032 - val_accuracy: 0.9003\n",
            "Epoch 15/50\n",
            "1716/1716 [==============================] - 122s 71ms/step - loss: 0.3316 - accuracy: 0.8875 - val_loss: 0.1394 - val_accuracy: 0.9509\n",
            "Epoch 16/50\n",
            "1716/1716 [==============================] - 121s 70ms/step - loss: 0.3130 - accuracy: 0.8927 - val_loss: 0.1565 - val_accuracy: 0.9439\n",
            "Epoch 17/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.2998 - accuracy: 0.9007 - val_loss: 0.1464 - val_accuracy: 0.9462\n",
            "Epoch 18/50\n",
            "1716/1716 [==============================] - 121s 70ms/step - loss: 0.2971 - accuracy: 0.9012 - val_loss: 0.1052 - val_accuracy: 0.9607\n",
            "Epoch 19/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.2919 - accuracy: 0.9021 - val_loss: 0.1923 - val_accuracy: 0.9308\n",
            "Epoch 20/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 0.2870 - accuracy: 0.9044 - val_loss: 0.1732 - val_accuracy: 0.9389\n",
            "Epoch 21/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 0.2667 - accuracy: 0.9110 - val_loss: 0.1035 - val_accuracy: 0.9639\n",
            "Epoch 22/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.2530 - accuracy: 0.9123 - val_loss: 0.2261 - val_accuracy: 0.9296\n",
            "Epoch 23/50\n",
            "1716/1716 [==============================] - 119s 70ms/step - loss: 0.2690 - accuracy: 0.9093 - val_loss: 0.1517 - val_accuracy: 0.9578\n",
            "Epoch 24/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.2366 - accuracy: 0.9208 - val_loss: 0.1382 - val_accuracy: 0.9483\n",
            "Epoch 25/50\n",
            "1716/1716 [==============================] - 120s 70ms/step - loss: 0.2346 - accuracy: 0.9226 - val_loss: 0.0992 - val_accuracy: 0.9635\n",
            "Epoch 26/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 0.2315 - accuracy: 0.9253 - val_loss: 0.1122 - val_accuracy: 0.9663\n",
            "Epoch 27/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 0.2232 - accuracy: 0.9237 - val_loss: 0.0538 - val_accuracy: 0.9826\n",
            "Epoch 28/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 0.2336 - accuracy: 0.9241 - val_loss: 0.1448 - val_accuracy: 0.9569\n",
            "Epoch 29/50\n",
            "1716/1716 [==============================] - 119s 69ms/step - loss: 0.2093 - accuracy: 0.9313 - val_loss: 0.1256 - val_accuracy: 0.9653\n",
            "Epoch 30/50\n",
            "1716/1716 [==============================] - 119s 70ms/step - loss: 0.2168 - accuracy: 0.9294 - val_loss: 0.0915 - val_accuracy: 0.9700\n",
            "Epoch 31/50\n",
            " 248/1716 [===>..........................] - ETA: 1:36 - loss: 0.2145 - accuracy: 0.9284"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q3Zpr46dsij"
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = # Your Code Here\n",
        "val_acc = # Your Code Here\n",
        "loss = # Your Code Here\n",
        "val_loss = # Your Code Here\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}